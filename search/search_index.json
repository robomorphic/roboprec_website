{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to RoboPrec","text":"<p>RoboPrec is a verification\u2011aware compiler pipeline for numerical workloads, built and evaluated on robotics kernels (rigid body dynamics, kinematics, etc.), but applicable to any computation that can be written in its Rust frontend.</p> <p>It is especially useful when you want to:</p> <ul> <li>Run robotics or other numeric kernels on microcontrollers or embedded SoCs with fast fixed-point instead of emulated <code>double</code>.</li> <li>Still benefit from fixed-point or mixed precision on desktop/server CPUs, where some kernels can be faster than <code>double</code>.</li> <li>Know exactly how much numerical error you introduce and prove it stays within bounds.</li> <li>Generate optimized C code that drops into existing C/C++ stacks.</li> </ul> <p>Under the hood, RoboPrec is a Rust library and analysis + codegen pipeline that connects your code to formal numerical analysis tools, then back to C code.</p>"},{"location":"#why-roboprec","title":"Why RoboPrec","text":"<ul> <li>Robotics\u2011first, numerics\u2011general: designed around rigid body dynamics and robot models, but the analysis + codegen pipeline works for any scalar/vector/matrix computation.</li> <li>Embedded and desktop:<ul> <li>On microcontrollers, fixed-point often gives order\u2011of\u2011magnitude speedups over <code>double</code> with formal guarantees.</li> <li>On modern CPUs, we show that fixed\u2011point can still match or beat <code>double</code> on some hot kernels.</li> </ul> </li> <li>From types to guarantees:<ul> <li>Static range and error analysis per variable.</li> <li>Support for <code>Float32</code>, <code>Float64</code>, and fixed-point (mixed or uniform).</li> <li>Verified code ready for CPUs, microcontrollers, or FPGAs.</li> </ul> </li> </ul> <p>Headline results from the paper:</p> <ul> <li>Up to 122x faster than <code>double</code> on some microcontrollers.</li> <li>On desktop CPUs, 32\u2011bit fixed-point can match or beat <code>double</code> on key kernels.</li> <li>For many dynamics workloads, fixed32 is more accurate than <code>float</code> in worst\u2011case bounds.</li> </ul>"},{"location":"#next-steps","title":"Next steps","text":"<ul> <li>New here? Start with Getting Started.</li> <li>Curious about the internals? See Framework Overview.</li> <li>Want the numbers? Check Benchmarks.</li> <li>Citing RoboPrec? See Publications.</li> </ul>"},{"location":"benchmarks/","title":"Benchmarks and Results","text":"<p>This page summarizes the evaluation from the RoboPrec paper for robotics workloads, and illustrates how the same pipeline can inform precision choices for other numeric code.</p> <p>For full details, see the paper and the figures referenced below.</p>"},{"location":"benchmarks/#workloads-robots-and-platforms","title":"Workloads, robots, and platforms","text":"<ul> <li>Algorithms: forward kinematics (FK), RNEA, RNEA derivatives.</li> <li>Robots: RoArm\u2011M2, RoArm\u2011M3, Indy7, Franka Emika Panda.</li> <li>Hardware:<ul> <li>Embedded: RP2040, RP2350\u2011RISC\u2011V, RP2350\u2011ARM.</li> <li>Desktop/server\u2011class: Raspberry Pi 5, Intel i7\u201114700K.</li> </ul> </li> </ul> <p>All code is compiled with <code>g++ -O3</code>.</p>"},{"location":"benchmarks/#performance-across-cpus","title":"Performance across CPUs","text":"<p>RoboPrec measures how <code>double</code>, <code>float</code>, and various fixed\u2011point formats perform on each platform. The main performance plots in the paper are:</p> <p> Figure: Runtimes across embedded CPUs (RP2040, RP2350\u2011RISC\u2011V, RP2350\u2011ARM). </p> <p> Figure: Runtimes on non\u2011embedded CPUs (Raspberry Pi 5, Intel i7\u201114700K). </p> <p>Key observations:</p> <p>Embedded (no / limited FPUs)</p> <ul> <li>On RP2040 and RP2350\u2011RISC\u2011V (no FPU):<ul> <li><code>double</code> is software\u2011emulated and very slow.</li> <li>RoboPrec\u2011generated fixed\u2011point code (e.g., 32\u2011bit fixed) can be an order of magnitude faster than <code>float</code>, and up to ~\\(122\\times\\) faster than <code>double</code> on some kernels.</li> </ul> </li> <li>On RP2350\u2011ARM (single\u2011precision FPU):<ul> <li><code>float</code> is usually the fastest choice.</li> <li>Fixed\u2011point is still faster than <code>double</code>, and can be attractive when you need better accuracy than <code>float</code> (see below).</li> </ul> </li> </ul> <p>Desktop / server CPUs</p> <ul> <li>On Raspberry Pi 5, <code>double</code> tends to be the best trade\u2011off.</li> <li>On Intel i7\u201114700K:</li> <li>Uniform fixed\u2011point (e.g., fixed32) can match or exceed <code>double</code> performance (\u22481.0\u20131.4\u00d7 speedups on some kernels).</li> </ul> <p>Even though RoboPrec is motivated by embedded robotics, these results suggest that precision tuning can also matter on full CPUs, especially for hotspots inside larger controllers or simulators.</p>"},{"location":"benchmarks/#worstcase-error-guarantees","title":"Worst\u2011case error guarantees","text":"<p>RoboPrec uses static analysis to compute worst\u2011case numeric error for each datatype and workload. The paper\u2019s worst\u2011case error figure is:</p> <p> Figure: Worst\u2011case error bounds across datatypes, robots, and algorithms.</p> <p>Highlights:</p> <ul> <li>As expected, <code>double</code> gives the tightest bounds.</li> <li>A key result for robotics and more general numerics:</li> </ul> <p>For many dynamics\u2011style kernels, 32\u2011bit fixed\u2011point (<code>fixed32</code>) has better worst\u2011case error bounds than <code>float</code>, even though both use 32 bits.</p> <ul> <li>Across our case studies, fixed32 shows \\(2.5\\times\\)\u2013\\(30.4\\times\\) smaller worst\u2011case error than <code>float</code>, depending on the workload.</li> <li>For very complex workloads (e.g., RNEA derivatives on 7\u2011DOF arms), some fixed\u2011point formats hit potential overflow in the analysis. RoboPrec then refuses to certify those precisions, which is exactly the kind of failure mode we want to expose before deployment.</li> </ul> <p>These guarantees apply to robotics, but the same reasoning extends to any numeric kernel where you can specify input ranges.</p> <p>For more detailed methodology and additional plots, please refer to the RoboPrec paper.</p>"},{"location":"community/","title":"Community and Contact","text":"<p>RoboPrec is an open-source project aimed at making numerically reliable embedded computing for robotics practical and accessible.</p>"},{"location":"community/#getting-help","title":"Getting help","text":"<p>For questions, bug reports, or feature requests:</p> <ul> <li>Open an issue on GitHub: https://github.com/robomorphic/roboprec/issues</li> </ul> <p>When reporting a problem, please include:</p> <ul> <li>Your platform (OS, compiler, CPU / microcontroller).</li> <li>RoboPrec commit hash or version.</li> <li>The precision configuration you used (e.g., <code>Float64</code>, <code>Float32</code>, specific fixed-point format).</li> <li>A minimal code example if possible.</li> </ul>"},{"location":"community/#contributing","title":"Contributing","text":"<p>Contributions are welcome. Useful ways to contribute include:</p> <ul> <li>Adding new kernels.</li> <li>Extending RoboPrec to new analysis back-ends or target platforms (e.g., additional FPGA flows).</li> <li>Improving documentation and examples.</li> <li>Benchmarking RoboPrec in new application domains (e.g., perception, planning, control).</li> </ul>"},{"location":"community/#license","title":"License","text":"<p>RoboPrec is released under an open-source license (see the <code>LICENSE</code> file in the repository for details). This generally permits research, academic, and commercial use, subject to the conditions in that file.</p>"},{"location":"community/#contact","title":"Contact","text":"<p>For collaborations or press inquiries, please contact the authors via their institutional email addresses as listed in the RoboPrec paper.</p>"},{"location":"framework/","title":"RoboPrec Framework Overview","text":"<p>RoboPrec is a framework for compiling robotics algorithms to embedded platforms with provable numerical accuracy guarantees across mixed-precision datatypes. It combines a Rust-based frontend, formal analysis of numerical error, and optimized C / fixed-point code generation.</p> <p>RoboPrec was originally introduced in the paper:</p> <p>RoboPrec: Enabling Reliable Embedded Computing for Robotics by Providing Accuracy Guarantees Across Mixed-Precision Datatypes Alp Eren Yilmaz, Thomas Bourgeat, Lillian Pentecost, Brian Plancher, Sabrina M. Neuman</p>"},{"location":"framework/#high-level-goals","title":"High-level goals","text":"<p>RoboPrec is designed to help robotics practitioners:</p> <ul> <li>Safely deploy compute-heavy robotics kernels (e.g., rigid body dynamics) on low-power embedded hardware.</li> <li>Systematically explore trade-offs between datatype, performance, and accuracy.</li> <li>Obtain formal, worst-case error bounds instead of ad-hoc testing.</li> <li>Integrate with existing robotics stacks by generating plain C or ap_fixed-style code.</li> </ul> <p>At a high level, RoboPrec answers questions like:</p> <ul> <li>\"Can I run this algorithm with 32-bit fixed-point on a microcontroller and still be safe?\"</li> <li>\"How much performance do I gain by moving from double to fixed-point, and what is the worst-case numerical error?\"</li> </ul>"},{"location":"framework/#framework-overview","title":"Framework Overview","text":"<p>This page gives you the mental model for RoboPrec in one screen.</p>"},{"location":"framework/#what-roboprec-does","title":"What RoboPrec does","text":"<p>RoboPrec takes a robotics kernel written in Rust and produces verified C / fixed-point code:</p> <ol> <li>You write the algorithm using RoboPrec\u2019s linear algebra types (<code>Scalar</code>, <code>Vector</code>, <code>Matrix</code>).</li> <li>RoboPrec unrolls and simplifies it into an analysis-friendly DSL.</li> <li>A back-end analysis tool (currently Daisy) computes ranges and worst\u2011case errors for a chosen precision.</li> <li>RoboPrec generates optimized C code (float, double, or fixed-point) that respects those bounds.</li> </ol> <p>You get code you can deploy on microcontrollers, CPUs, or FPGAs\u2014with a quantitative story about numerical error.</p>"},{"location":"framework/#three-key-stages","title":"Three key stages","text":"<p>1. Transpiler (Rust \u2192 DSL)</p> <ul> <li>Input: Rust code using <code>Scalar</code> / <code>Vector</code> / <code>Matrix</code> and robot models.</li> <li>Actions:</li> <li>Unroll loops.</li> <li>Expand matrix/vector ops into scalar arithmetic.</li> <li>Output: a straight\u2011line program in an analysis DSL.</li> </ul> <p>2. Error analysis</p> <ul> <li>Input: simplified program + input ranges + target precision.</li> <li>Uses Daisy to compute for every variable:<ul> <li>Value range.</li> <li>Worst-case roundoff error.</li> </ul> </li> <li>Supports:<ul> <li><code>Float32</code>, <code>Float64</code>.</li> <li>Fixed-point in mixed or uniform precision modes.</li> <li>mixed version sets the minimum number of integer bits for each variable</li> <li>uniform version expects the user to set the integer bits for each variable</li> </ul> </li> </ul> <p>3. Code generation</p> <ul> <li>Produces C code matching the chosen datatype:</li> <li>Plain <code>double</code> / <code>float</code>.</li> <li>Integer-emulated fixed-point (or <code>ap_fixed</code>-style for HLS).</li> <li>Code is straight\u2011line and vectorization\u2011friendly, ideal for embedded targets and SIMD.</li> </ul>"},{"location":"framework/#limitations","title":"Limitations","text":"<p>RoboPrec can only handle programs with static dataflow. Therefore, conditionals and loops must be handled carefully. For example, the following program is valid, because the executed operations are the same regardless of inputs:</p> <pre><code>// 1. Define input 'x' with range [0.0, 1.0] and a default value for testing\nlet input_range = (Real::from_f64(0.0), Real::from_f64(1.0));\nlet default_val = 0.5;\nlet mut x = add_input_scalar(\"x\", input_range, default_val);\n\n// 2. Perform the computation\nfor i in 0..3 {\n    println!(\"Iteration {}\", i);\n    x = &amp;x * &amp;x;\n    if i == 0 {\n        x = x + Scalar!(1.0);\n    }\n    if i == 2 {\n        register_scalar_output(&amp;mut x, \"intermediate_output\");\n    }\n}\n...\n</code></pre>"},{"location":"framework/#examples","title":"Examples","text":"<ul> <li> <p>Rigid-body dynamics kernels:</p> <ul> <li>Forward kinematics (FK)</li> <li>RNEA</li> <li>RNEA derivatives</li> </ul> </li> <li> <p>Robot models:</p> <ul> <li>RoArm\u2011M2 (4\u2011DOF) </li> <li>RoArm\u2011M3 (5\u2011DOF)</li> <li>Indy7 (6\u2011DOF)</li> <li>Franka Emika Panda (7\u2011DOF)</li> </ul> </li> </ul> <p>These serve both as benchmarks (see Benchmarks) and as reference examples for writing your own kernels.</p>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the Rust programming language installed. If you do not have it, you can install it using rustup.</p>"},{"location":"getting_started/#supported-platforms","title":"Supported Platforms","text":"<ul> <li>\u2705 Ubuntu (tested on 22.04)</li> <li>\u274c macOS (work in progress)</li> <li>\u274c Windows</li> </ul>"},{"location":"getting_started/#installation","title":"Installation","text":"<p>To get started, clone the repository and build with Cargo.</p> <p>If you want to work on RoboPrec directly:</p> <pre><code>git clone https://github.com/robomorphic/roboprec\ncd roboprec\ncargo build --release\n</code></pre> <p>The compiled binary will be in <code>target/release</code>.</p> <p>If you want to use RoboPrec as a library in your own project, add it to your <code>Cargo.toml</code>:</p> <pre><code>[dependencies]\nroboprec = { git = \"https://github.com/robomorphic/roboprec.git\" }\n</code></pre>"},{"location":"getting_started/#quick-start","title":"Quick Start","text":"<p>The following example demonstrates how to define a simple computation, analyze it, and inspect the results.</p>"},{"location":"getting_started/#1-define-the-computation-in-rust","title":"1. Define the Computation in Rust","text":"<p>First, we write a Rust program that defines the computation we want to analyze. In this example, we'll compute \\(x^3\\).</p> <p>We specify:</p> <ol> <li>Inputs: Variable <code>x</code> with a range of \\([0.0, 1.0]\\).</li> <li>Computation: <code>x * x * x</code>.</li> <li>Outputs: The result is registered as <code>output</code>.</li> <li>Configuration: We choose the target precision (e.g., <code>Float64</code> or <code>Fixed</code>) and output location.</li> </ol> <pre><code>// 1. Define input 'x' with range [0.0, 1.0] and a default value for testing\nlet input_range = (Real::from_f64(0.0), Real::from_f64(1.0));\nlet default_val = 0.5;\nlet x = add_input_scalar(\"x\", input_range, default_val);\n\n// 2. Perform the computation\nlet mut res = x * x * x;\n\n// 3. Register the result\nregister_scalar_output(&amp;mut res, \"output\");\n\n// (Optional) Verify correctness in Rust\nassert!(res.value.to_f64() == default_val.powi(3));\n\n// 4. Configure and run analysis\nlet config = Config {\n    precision: Precision::Float64, // Target precision\n    codegen_dir: PathBuf::from(\"output/\"),\n    codegen_filename: \"codegen\".to_string(),\n};\n\nanalysis(config);\n</code></pre>"},{"location":"getting_started/#2-generate-c-code","title":"2. Generate C Code","text":"<p>RoboPrec automatically generates C code based on your configuration.</p>"},{"location":"getting_started/#option-a-double-precision-float64","title":"Option A: Double Precision (<code>Float64</code>)","text":"<p>If we select <code>Precision::Float64</code>, the pipeline generates standard C code using <code>double</code>:</p> <pre><code>typedef struct {\n    double output;\n} codegen_output_t;\n\ncodegen_output_t codegen(\n    double x\n) {\n    double x_mul_x = (x * x);\n    double x_mul_x_mul_x = (x_mul_x * x);\n    double output = x_mul_x_mul_x;\n\n    return {\n        output,\n    };\n}\n</code></pre>"},{"location":"getting_started/#option-b-fixed-point-optimization","title":"Option B: Fixed-Point Optimization","text":"<p>If we switch the configuration to fixed-point (e.g., <code>Precision::Fixed { total_bits: 16, fractional_bits: -1 }</code>), RoboPrec performs a powerful optimization:</p> <ol> <li>It automatically selects the optimal number of fractional bits for each variable to maximize precision while preventing overflow.</li> <li>It generates bit-exact C code using integer arithmetic.</li> </ol> <pre><code>typedef struct {\n  int16_t output;\n} codegen_output_t;\n\ncodegen_output_t codegen(int16_t x) {\n    // RoboPrec automatically handles shifting and casting\n    int16_t x_mul_x = (int16_t) ((((int32_t) (x) * (int32_t) (x)) &gt;&gt; 14));\n    int16_t x_mul_x_mul_x = (int16_t) ((((int32_t) (x_mul_x) * (int32_t) (x)) &gt;&gt; 14));\n    int16_t output = x_mul_x_mul_x;\n\n    return { output };\n}\n</code></pre> <p>Why <code>int32_t</code> casts?</p> <p>Even though the variables are stored as <code>int16_t</code>, intermediate calculations (like multiplication) are cast to <code>int32_t</code>. This is necessary because multiplying two 16-bit numbers produces a 32-bit result. RoboPrec handles these promotions automatically to prevent overflow before shifting back down.</p> <p>Why choose this approach?</p> <p>This version is highly efficient for embedded systems:</p> <ul> <li>Smaller I/O: Inputs and outputs are 16-bit integers instead of 64-bit doubles.</li> <li>Faster Arithmetic: Integer operations are typically faster than floating-point emulation on microcontrollers.</li> </ul>"},{"location":"getting_started/#option-c-fixed-point-with-automatic-conversion","title":"Option C: Fixed-Point with Automatic Conversion","text":"<p>If you want the speed of fixed-point internals but need to integrate with an existing system that uses <code>double</code>, RoboPrec can generate automatic conversion wrappers.</p> <p>This allows you to pass <code>double</code> in and get <code>double</code> out, while the heavy lifting is done in optimized fixed-point arithmetic:</p> <pre><code>typedef struct {\n    double output;\n} codegen_output_t;\n\ncodegen_output_t codegen(double _double_x) {\n    // 1. Convert input double to fixed-point (int16_t)\n    int16_t x = (int16_t)(_double_x * (1 &lt;&lt; 14)); \n\n    // 2. Perform optimized fixed-point arithmetic\n    int16_t x_mul_x = (int16_t) ((((int32_t) (x) * (int32_t) (x)) &gt;&gt; 14));\n    int16_t x_mul_x_mul_x = (int16_t) ((((int32_t) (x_mul_x) * (int32_t) (x)) &gt;&gt; 14));\n    int16_t output = x_mul_x_mul_x;\n\n    return {\n        // 3. Convert result back to double\n        ((double)output) / (1 &lt;&lt; 14), \n    };\n}\n</code></pre>"},{"location":"getting_started/#3-analysis-results","title":"3. Analysis Results","text":"<p>The analysis provides detailed reports on the value range and accumulated error for each variable in the program.</p>"},{"location":"getting_started/#range-analysis","title":"Range Analysis","text":"<p>The following table shows the inferred value range for each variable for the example code above.</p> Variable Range <code>output</code> <code>[0, 1]</code> <code>x_mul_x_mul_x</code> <code>[0, 1]</code> <code>x_mul_x</code> <code>[0, 1]</code> <code>x</code> <code>[0, 1]</code>"},{"location":"getting_started/#error-analysis","title":"Error Analysis","text":"<p>This table presents the worst-case accumulated error for each variable for the example code above.</p> Variable Accumulated Error (\u00b1) <code>output</code> <code>4.66e-9</code> <code>x_mul_x_mul_x</code> <code>4.66e-9</code> <code>x_mul_x</code> <code>2.79e-9</code> <code>x</code> <code>9.31e-10</code>"},{"location":"publications/","title":"Publications","text":"<p>If you use RoboPrec in academic work, please cite the following paper:</p> <p>RoboPrec: Enabling Reliable Embedded Computing for Robotics by Providing Accuracy Guarantees Across Mixed-Precision Datatypes Alp Eren Yilmaz, Thomas Bourgeat, Lillian Pentecost, Brian Plancher, Sabrina M. Neuman IEEE Robotics and Automation Letters (RA-L), 2025.</p> <p>A BibTeX entry will be provided once the final version and DOI are available.</p>"}]}